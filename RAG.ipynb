{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-based QA System for Meeting Records  \n",
    "# 基於RAG的會議記錄問答系統"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 引入必要套件與初始化參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from IPython.display import display, Markdown\n",
    "import sqlite3\n",
    "import json\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定模型參數與索引路徑\n",
    "DOCS_FOLDER = \"/Users/gastove/Documents/SuperGIS/meeting_data\"\n",
    "EMBEDDING_MODEL_NAME = 'Alibaba-NLP/gte-Qwen2-1.5B-instruct'\n",
    "LLM_MODEL_NAME = \"taide/Llama3-TAIDE-LX-8B-Chat-Alpha1\"\n",
    "FAISS_INDEX_PATH = \"faiss_index.bin\"\n",
    "FAISS_WEIGHT = 0.6\n",
    "BM25_WEIGHT = 0.4\n",
    "BM25_TOP_K = 9\n",
    "RETRIEVE_TOP_K = 4\n",
    "MAX_NEW_TOKENS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 從 SQLite 資料庫讀取向量與原始文件內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('documents.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 'document_vectors' 資料表中載入：\n",
    "cursor.execute(\"SELECT content, file_name FROM document_vectors\")\n",
    "rows = cursor.fetchall()\n",
    "documents, file_names = zip(*rows) if rows else ([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取向量\n",
    "cursor.execute(\"SELECT vector FROM document_vectors\")\n",
    "vectors = [np.array(json.loads(row[0]), dtype=np.float32) for row in cursor.fetchall()]\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 載入 FAISS 向量索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已載入 FAISS 索引，共有 14 筆資料\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(FAISS_INDEX_PATH):\n",
    "    index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "    print(f\"已載入 FAISS 索引，共有 {index.ntotal} 筆資料\")\n",
    "else:\n",
    "    raise ValueError(\"FAISS 索引不存在，請先執行 database.py 生成索引。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 建立 BM25 字詞檢索器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/30/fhg1jm9j1zb9v37xrv1_hjdc0000gn/T/jieba.cache\n",
      "Loading model cost 0.332 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "tokenized_docs = [list(jieba.cut(doc.lower())) for doc in documents]\n",
    "bm25 = BM25Okapi(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 定義混合檢索：FAISS + BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6e138c58ef4b82af849f702ee506c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedder = SentenceTransformer(EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(prompt, top_k=RETRIEVE_TOP_K):\n",
    "    \"\"\"\n",
    "    使用 FAISS 向量相似度 + BM25 字詞相似度 綜合加權排序\n",
    "    \"\"\"\n",
    "    # Encode 使用者輸入為向量\n",
    "    query_embedding = embedder.encode(\n",
    "        [prompt], convert_to_tensor=False).astype(\"float32\")\n",
    "\n",
    "    # FAISS 檢索：先多抓一些候選資料（ex: top_k * 3）\n",
    "    faiss_top_k = top_k * 3\n",
    "    distances, indices = index.search(query_embedding, faiss_top_k)\n",
    "\n",
    "    # FAISS 分數轉成相似度（距離越小分數越高）\n",
    "    faiss_scores = -distances[0]  # FAISS 距離越小越相關\n",
    "\n",
    "    # BM25 分數\n",
    "    tokenized_query = list(jieba.cut(prompt.lower()))\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "    # 綜合排序：加權平均\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        combined_score = FAISS_WEIGHT * faiss_scores[i] + BM25_WEIGHT * bm25_scores[idx]\n",
    "        results.append((combined_score, documents[idx], file_names[idx]))\n",
    "\n",
    "    # 依分數排序\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    # 取前 top_k 筆\n",
    "    top_docs = results[:top_k]\n",
    "    return [doc for _, doc, _ in top_docs], [fname for _, _, fname in top_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1. 支援民國日期的檢索過濾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_from_question(text):\n",
    "    \"\"\"從問題中提取民國日期（如112年11月6日）\"\"\"\n",
    "    match = re.search(r'(\\d{3})年(\\d{1,2})月(\\d{1,2})日', text)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}年{match.group(2)}月{match.group(3)}日\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def retrieve_docs_with_date_filter(prompt, top_k=RETRIEVE_TOP_K):\n",
    "    \"\"\"根據問題中的日期，優先檢索包含該日期的會議記錄\"\"\"\n",
    "    target_date = extract_date_from_question(prompt)\n",
    "    if not target_date:\n",
    "        return retrieve_docs(prompt)  # 若無日期則走原本流程\n",
    "\n",
    "    # 過濾只包含該日期的文件\n",
    "    filtered = [(doc, fname) for doc, fname in zip(documents, file_names)\n",
    "                if target_date in doc]\n",
    "\n",
    "    if not filtered:\n",
    "        return retrieve_docs(prompt)  # 若找不到含該日期的資料，也走原流程\n",
    "\n",
    "    # 對過濾後資料跑 FAISS 和 BM25\n",
    "    filtered_docs, filtered_fnames = zip(*filtered)\n",
    "    tokenized_filtered = [list(jieba.cut(doc.lower()))\n",
    "                          for doc in filtered_docs]\n",
    "    bm25_filtered = BM25Okapi(tokenized_filtered)\n",
    "\n",
    "    # 向量化 Query\n",
    "    query_embedding = embedder.encode(\n",
    "        [prompt], convert_to_tensor=False).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, top_k * 3)\n",
    "    faiss_scores = -distances[0]\n",
    "\n",
    "    # 配對分數\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx < len(filtered_docs):\n",
    "            bm25_score = bm25_filtered.get_scores(\n",
    "                list(jieba.cut(prompt.lower())))[idx]\n",
    "            combined = FAISS_WEIGHT * \\\n",
    "                faiss_scores[i] + BM25_WEIGHT * bm25_score\n",
    "            results.append(\n",
    "                (combined, filtered_docs[idx], filtered_fnames[idx]))\n",
    "\n",
    "    results.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_docs = results[:top_k]\n",
    "    return [doc for _, doc, _ in top_docs], [fname for _, _, fname in top_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 設定 HuggingFace 的 LLM 回答模型（TAIDE）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llm():\n",
    "    \"\"\"設置 TAIDE 生成模型\"\"\"\n",
    "    llm_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=LLM_MODEL_NAME,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "        num_beams=1,      # 使用束搜索\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=llm_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7bc68b2f0f4c9bb2da8f34a1f27c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "llm = setup_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 處理輸入關鍵詞與數字格式（提升抽詞準確性）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numbers(text):\n",
    "    \"\"\"\n",
    "    處理數字相關詞組：日期、次數、金額\n",
    "    例如：114年1月20日、第3次會議、500萬元\n",
    "    \"\"\"\n",
    "    # 日期標準化（例：114年1月20日）\n",
    "    text = re.sub(r'(\\d{3})年(\\d{1,2})月(\\d{1,2})日', r'\\1年\\2月\\3日', text)\n",
    "\n",
    "    # 處理「第3次會議」、「第5次討論」\n",
    "    text = re.sub(r'第(\\d+)次(會議|討論|會面)', r'第\\1次_\\2', text)\n",
    "\n",
    "    # 處理金額（例：500萬元）\n",
    "    text = re.sub(r'(\\d+)(萬|千)?元', r'\\1\\2元', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model=embedder)\n",
    "\n",
    "def extract_keywords(text, top_k=5):\n",
    "    \"\"\"\n",
    "    使用 KeyBERT 進行語意關鍵詞抽取，並先處理數字格式避免被拆斷\n",
    "    \"\"\"\n",
    "    clean_text = normalize_numbers(text)\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        clean_text,\n",
    "        keyphrase_ngram_range=(1, 2),\n",
    "        stop_words=None,  # 中文建議不要用英文停用詞\n",
    "        top_n=top_k\n",
    "    )\n",
    "    return [kw for kw, score in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 根據檢索資料與提示詞生成初步回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根據檢索到的資料庫生成初步回答\n",
    "def generate_initial_answer(question):\n",
    "    \n",
    "    keywords = extract_keywords(question)\n",
    "\n",
    "    prompt_template_with_history = \"\"\"\n",
    "    請根據提供的會議記錄回答問題，並確保答案符合以下條件：\n",
    "    1. 只根據會議記錄內容作答，不可自行補充未出現的資訊。\n",
    "    2. 若檢索到的資訊不足，請回答「資料中無答案」。\n",
    "    3. 你的回答應該重點關注以下關鍵詞：{keywords}\n",
    "    4. 若問題包含具體時間，務必根據該時間對應的記錄作答。\n",
    "\n",
    "    \n",
    "    檢索到的會議記錄：\n",
    "    {context}\n",
    "\n",
    "    問題：\n",
    "    {question}\n",
    "\n",
    "    請直接輸出最重點的文字答案，務必不要重複一樣的文句：\n",
    "    \"\"\"\n",
    "\n",
    "    retrieved_docs, retrieved_files = retrieve_docs_with_date_filter(question)\n",
    "    context_parts = [f\"【{file}】\\n{text}\" for file, text in zip(retrieved_files, retrieved_docs)]\n",
    "    # print(context_parts)\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    full_prompt = prompt_template_with_history.format(\n",
    "        context=context, \n",
    "        keywords=\", \".join(keywords),\n",
    "        question=question\n",
    "    )\n",
    "    outputs = llm.invoke(full_prompt)\n",
    "    if isinstance(outputs, list) and outputs and isinstance(outputs[0], dict):\n",
    "        answer = outputs[0].get(\"generated_text\", str(outputs[0]))\n",
    "    else:\n",
    "        answer = str(outputs)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 自我檢查與修正回答內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將初步回答與原始問題丟入修正提示，讓模型自我檢查並產生改進答案\n",
    "def refine_answer(question, initial_answer):\n",
    "    \n",
    "    refine_template = \"\"\"\n",
    "    原始問題：\n",
    "    {question}\n",
    "\n",
    "    初步回答：\n",
    "    {initial_answer}\n",
    "\n",
    "    詳細檢查初步回答是否有誤，如果有誤，務必修正。\n",
    "    \"\"\"\n",
    "    refine_prompt = refine_template.format(question=question, initial_answer=initial_answer)\n",
    "\n",
    "    outputs = llm.invoke(refine_prompt)\n",
    "    if not outputs or not isinstance(outputs, list) or not outputs[0]:\n",
    "        return initial_answer  # 避免無限迴圈，回傳原始回答\n",
    "    return outputs[0].get(\"generated_text\", str(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 主流程整合：從輸入問題到最終答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    try:\n",
    "        initial = generate_initial_answer(question)\n",
    "        refined = refine_answer(question, initial)\n",
    "        return refined\n",
    "    except Exception as e:\n",
    "        return f\"發生錯誤：{e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. CLI 測試介面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 114年1月20日有哪些人出席會議\n",
    "# 114年2月11日有哪些人出席會議\n",
    "# 112年11月6日有哪些人出席會議"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始對話 (輸入 'exit' 結束對話)：\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**User:** 112年11月6日有哪些人出席會議"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Bot:**\n",
       "112年11月6日出席會議人員包括：蔡組長森洲、崧旭資訊公司：蕭惠文、陳禹妏、黃平耕、施宏諭、配電處：陳清華、戴禮治、王建策、楊侑霖、薛博駿、業務處：楊琇帆、邱瓊慧、陳朝麒、陳冠友、陳芸亭、詹宜芳、張曼璿、彭治弘、資訊處：楊育昇、綜研所：游晴幃、沈宜絹。    \n",
       "」"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**User:** 114年2月11日有哪些人出席會議"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Bot:**\n",
       "114年2月11日出席會議人員包括蔡組長森洲、崧旭：蕭惠文、陳禹妏、黃平耕、施宏諭、配電處：李蕙卉、薛博駿、綜研所：王晴。    \n",
       "」"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**User:** 114年1月20日有哪些人出席會議"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Bot:**\n",
       "114年1月20日出席「電度表、變比器資訊數位化管理之研究」會議的人員包括：蔡組長森洲、王晴（綜研所）、薛博駿（配電處）、蕭惠文（崧旭）、陳禹妏（崧旭）、黃平耕（崧旭）、施宏諭（崧旭）、李蕙卉（配電處）。    \n",
       "」"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "對話結束。\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"開始對話 (輸入 'exit' 結束對話)：\")\n",
    "    try:\n",
    "        while True:\n",
    "            user_input = input(\"\")\n",
    "            if user_input.strip().lower() == \"exit\":\n",
    "                print(\"對話結束。\")\n",
    "                break\n",
    "            display(Markdown(f\"**User:** {user_input}\"))\n",
    "            answer_text = generate_answer(user_input)\n",
    "            display(Markdown(f\"**Bot:**\\n{answer_text}\"))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n對話已手動結束。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
